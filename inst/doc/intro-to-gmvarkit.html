<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="author" content="Savi Virolainen" />

<meta name="date" content="2019-07-04" />

<title>Introduction to gmvarkit</title>






<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#header {
text-align: center;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; }  code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Introduction to gmvarkit</h1>
<h4 class="author">Savi Virolainen</h4>
<h4 class="date">2019-07-04</h4>



<p>The package <code>gmvarkit</code> contains tools to estimate and analyze Gaussian Mixture Vector Autoregressive (GMVAR) model (see Kalliovirta et. al. 2016). This vignette does not explain details about the model and it’s assumed that the reader is familiar with the cited article(s).</p>
<p>The GMVAR models in <code>gmvarkit</code> are defined as class <code>gmvar</code> S3 objects whose can be created with the estimation function <code>fitGMVAR</code> or with the constructor function <code>GMVAR</code>. The created <code>gmvar</code> objects are then be conveniently used as main arguments in many other functions that allow, for example, model diagnostics, simulations and forecasting. Therefore, after estimating a GMVAR model it’s easy to use the other functions for further analyses. However some tasks, such as applying general linear constraints, creating GMVAR models without estimation or setting up initial population for the genetic algorithm employed by the estimation function, require accurate understanding on how the parameter vectors are constructed in this package.</p>
<p>The notations for (unconstrained) parameter vector are in line with the cited article by Kalliovirta et. al. (2016), but for clarity we repeat these notations in the first section of this vignette. In the second section we show how to apply general linear constraints to the autoregressive parameters of a GMVAR model. Two examples are given to demonstrate how to use the general formula. In the third section we have listed some useful functions and methods found in <code>gmvarkit</code> and briefly explain how they work and how to use them.</p>
<div id="general-notations-and-unconstrained-models" class="section level2">
<h2>General notations and unconstrained models</h2>
<div id="general-notations" class="section level3">
<h3>General notations</h3>
<p>Defining a GMVAR model requires specifying the autoregressive degree <em>p</em> and the number of mixture components <em>M</em>. The number of time series in the system is denoted by <em>d</em>, and it’s assumed that <em>d</em> is larger than one.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> The form of the parameter vector depends on whether an unconstrained or constrained model is considered.</p>
</div>
<div id="parameter-vector-of-unconstrained-model" class="section level3">
<h3>Parameter vector of unconstrained model</h3>
<p>The parameter vector for unconstrained model is of size <em>((M(pd^2+d(d+1)/2+1)-1)x1)</em> and has form <span class="math display">\[\boldsymbol{\theta} = (\boldsymbol{\upsilon_1},...,\boldsymbol{\upsilon_M},\alpha_1,...,\alpha_{M-1}),\enspace \text{where}\quad\quad\enspace\quad\]</span> <span class="math display">\[\boldsymbol{\upsilon_m}=(\phi_{m,0},\boldsymbol{\phi_m},\sigma_m)\enspace ((pd^2+d(d+1)/2)x1),\quad\quad\enspace\]</span> <span class="math display">\[\boldsymbol{\phi_m}=(vec(A_{m,1}),...,vec(A_{m,p}))\enspace (pd^2x1), \enspace \text{and}\quad\enspace\;\]</span> <span class="math display">\[\sigma_m=vech(\Omega_m)\enspace ((d(d+1)/2)x1),\enspace m=1,...,M.\]</span></p>
<p>Above <span class="math inline">\(\phi_{m,0}\)</span> denotes the intercept parameter of <em>m</em>:th mixture component, <span class="math inline">\(A_{m,i}\)</span> denotes the coefficient matrix of <em>m</em>:th mixture component and <em>i</em>:th lag, <span class="math inline">\(\Omega_m\)</span> denotes the (positive definite) error term covariance matrix, and <span class="math inline">\(\alpha_m\)</span> denotes the mixing weight parameter of <em>m</em>:th mixture component. <span class="math inline">\(vec()\)</span> is a vectorization operator that stacks columns of a matrix into a vector and <span class="math inline">\(vech()\)</span> stacks columns of a matrix from the main diagonal downwards (including the main diagonal) into a vector.</p>
<p>The parameter vector above has “intercept” parametrization, referring to the intercept terms <span class="math inline">\(\phi_{m,0}\)</span>. However, it’s also possible to use “mean” parametrization, where the intercept terms are simply replaced by the regimewise means <span class="math inline">\(\mu_m=(I_d-\sum_{i=1}^pA_{m,i})^{-1}\phi_{m,0}\)</span>.</p>
</div>
</div>
<div id="models-with-linear-constraints" class="section level2">
<h2>Models with linear constraints</h2>
<div id="general-linear-constraints-and-parameter-vector" class="section level3">
<h3>General linear constraints and parameter vector</h3>
<p>Imposing linear constraints on the autoregressive parameters of GMVAR model is straightforward in <code>gmvarkit</code>. The constraints are expressed in a rather general form allowing arbitrary linear constraints, but one needs to take the time to construct the constraint matrix carefully for each particular case.</p>
<p>We consider constraints of form <span class="math display">\[(\boldsymbol{\phi_1},...,\boldsymbol{\phi_M}) = \boldsymbol{C}\boldsymbol{\psi},\enspace \text{where}\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\enspace\]</span> <span class="math display">\[\boldsymbol{\phi_m}=(vec(A_{m,1}),...,vec(A_{m,p}))\enspace (pd^2x1), \enspace m=1,...,M,\]</span> <span class="math inline">\(\boldsymbol{C}\)</span> is known <span class="math inline">\((Mpd^2xq)\)</span> constraint matrix (of full column rank) and <span class="math inline">\(\boldsymbol{\psi}\)</span> is unknown <span class="math inline">\((qx1)\)</span> parameter vector.</p>
<p>The parameter vector for constrained model is size <em>((M(d+d(d+1)/2+1)+q-1)x1)</em> and has form <span class="math display">\[\boldsymbol{\theta} = (\phi_{1,0},...,\phi_{M,0},\boldsymbol{\psi},\alpha_1,...,\alpha_{M-1}),\]</span> where <span class="math inline">\(\boldsymbol{\psi}\)</span> is the <span class="math inline">\((qx1)\)</span> parameter vector containing constrained autoregressive parameters. As in the case of regular models, instead of the intercept parametrization that takes use of intercept terms <span class="math inline">\(\phi_{m,0}\)</span>, one may use the mean parametrization with regimewise means <span class="math inline">\(\mu_m\)</span> instead <em>(m=1,…,M)</em>.</p>
</div>
<div id="examples-of-linear-constraints" class="section level3">
<h3>Examples of linear constraints</h3>
<p>Consider the following two common uses for linear constraints: restricting the autoregressive parameters to be the same for all regimes and constraining some parameters to zero. Of course also some other constraints may be useful, but we chose to show illustrative examples of these two as they occur in the cited article by Kalliovirta et al. (2016).</p>
<div id="restricting-ar-parameters-to-be-the-same-for-all-regimes" class="section level4">
<h4>Restricting AR parameters to be the same for all regimes</h4>
<p>To restrict the AR parameters to be the same for all regimes, we want <span class="math inline">\(\boldsymbol{\phi_m}\)</span> to be the same for all <em>m=1,…,M</em>. The parameter vector <span class="math inline">\(\boldsymbol{\psi}\)</span> <span class="math inline">\((qx1)\)</span> then corresponds to any <span class="math inline">\(\boldsymbol{\phi_m}=\boldsymbol{\phi}\)</span>, and therefore <span class="math inline">\(q=pd^2\)</span>. For the constraint matrix we choose <span class="math display">\[\boldsymbol{C} = [I_{pd^2}:\cdots:I_{pd^2}]' \enspace (Mpd^2xpd^2),\]</span> that is, <em>M</em> pieces of <span class="math inline">\((pd^2xpd^2)\)</span> diagonal matrices stacked on top of each other, because then <span class="math display">\[\boldsymbol{C}\boldsymbol{\psi}=(\boldsymbol{\psi},...,\boldsymbol{\psi})=(\boldsymbol{\phi},...,\boldsymbol{\phi}).\]</span></p>
</div>
<div id="restricting-ar-parameters-to-be-the-same-for-all-regimes-and-constraining-non-diagonal-elements-of-coefficient-matrices-to-be-zero" class="section level4">
<h4>Restricting AR parameters to be the same for all regimes and constraining non-diagonal elements of coefficient matrices to be zero</h4>
<p>The previous example shows how to restrict the AR parameters to be the same for all regimes, but say we also want to constrain the non-diagonal elements of coefficient matrices <span class="math inline">\(A_{m,i}\)</span> <em>(m=1,…,M, i=1,…,p)</em> to be zero. We have the constrained parameter <span class="math inline">\(\boldsymbol{\psi}\)</span> <span class="math inline">\((qx1)\)</span> representing the unconstrained parameters <span class="math inline">\((\boldsymbol{\phi_1},...,\boldsymbol{\phi_M})\)</span>, where by assumption <span class="math inline">\(\boldsymbol{\phi_m}=\boldsymbol{\phi}=(vec(A_1),...,vec(A_p))\)</span> <span class="math inline">\((pd^2x1)\)</span> and the elements of <span class="math inline">\(vec(A_i)\)</span> <em>(i=1,…,p)</em> corresponding to the diagonal are zero.</p>
<p>For illustrative purposes, let’s consider a GMVAR model with autoregressive degree <em>p=2</em>, number of mixture components <em>M=2</em> and number of time series in the system <em>d=2</em>. Then we have <span class="math display">\[\boldsymbol{\phi}=(A_{1,(1,1)},0,0,A_{1,(2,2)},A_{2,(1,1)},0,0,A_{2,(2,2)}) \enspace (8x1) \enspace \text{and} \]</span> <span class="math display">\[\boldsymbol{\psi}=(A_{1,(1,1)},A_{1,(2,2)},A_{2,(1,1)},A_{2,(2,2)}) \enspace (4x1).\quad\quad\quad\quad\quad\enspace\]</span> By a direct calculation, we can see that choosing the constraint matrix <span class="math display">\[\boldsymbol{C}=\left[{\begin{array}{c}
   \boldsymbol{\tilde{c}} \\
   \boldsymbol{\tilde{c}} \\
  \end{array}}\right]
\enspace (Mpd^2x4),
\enspace \text{where}\]</span></p>
<p><span class="math display">\[\boldsymbol{\tilde{c}}=\left[{\begin{array}{cccc}
   1 &amp; 0 &amp; 0 &amp; 0 \\
   0 &amp; 0 &amp; 0 &amp; 0 \\
   0 &amp; 0 &amp; 0 &amp; 0 \\
   0 &amp; 1 &amp; 0 &amp; 0 \\
   0 &amp; 0 &amp; 1 &amp; 0 \\
   0 &amp; 0 &amp; 0 &amp; 0 \\
   0 &amp; 0 &amp; 0 &amp; 0 \\
   0 &amp; 0 &amp; 0 &amp; 1 \\
  \end{array}}\right]
\enspace (pd^2x4)\]</span> satisfies <span class="math inline">\(\boldsymbol{C}\boldsymbol{\psi}=(\boldsymbol{\phi},...,\boldsymbol{\phi}).\)</span></p>
</div>
</div>
</div>
<div id="functions-in-gmvarkit" class="section level2">
<h2>Functions in gmvarkit</h2>
<div id="estimating-a-gmvar-model" class="section level3">
<h3>Estimating a GMVAR model</h3>
<p><code>gmvarkit</code> provides the function <code>fitGMVAR</code> for estimating a GMVAR model. The maximum likelihood estimation is performed in two phases: in the first phase <code>fitGMVAR</code> uses a genetic algorithm to find starting values for gradient based variable metric algorithm, which it then uses to finalize the estimation in the second phase. It’s important to keep in mind that it’s not guaranteed that the numerical estimation algorithms end up in the global maximum point rather than a local one. Because of multimodality and challenging surface of the log-likelihood function, it’s actually expected that most of the estimation rounds won’t find the global maximum point. For this reason one should always perform multiple estimation rounds. Parallel computing is used to obtain the results faster. The number of CPU cores used can be set with the argument <code>ncores</code>, and the number of estimation rounds can be controlled with the argument <code>ncalls</code>.</p>
<p>If the model estimates poorly, it is often because the number of mixture components <em>M</em> is chosen too large. One may also adjust the settings of the genetic algorithm employed, or set up an initial population with guesses for the estimates. This can by done by passing arguments in <code>fitGMVAR</code> to the function <code>GAfit</code> which implements the genetic algorithm. To check the available settings, read the documentation <code>?GAfit</code>. If the iteration limit is reached when estimating the model, the function <code>iterate_more</code> can be used to finish the estimation.</p>
<p>Parameters of the estimated model are printed in an illustrative and easy to read form. In order to easily compare approximate standard errors to certain estimates, one can print the approximate standard errors of the estimates in the same form with the function <code>print_std_errors</code>. Numerical approximation of the gradient and Hessian matrix of the log-likelihood at the estimates can be obtained conveniently with the functions <code>get_gradient</code> and <code>get_hessian</code>, and eigenvalues of the Hessian can be obtained with the function <code>get_soc</code>.</p>
<p>The estimated objects have their own print, plot, and summary methods.</p>
</div>
<div id="model-diagnostics" class="section level3">
<h3>Model diagnostics</h3>
<p><code>gmvarkit</code> considers model diagnostics based on multivariate extension of quantile residuals (see Kalliovirta and Saikkonen 2010), whose are under the correct model specification asymptotically multivariate standard normal distributed. The quantile residual tests introduced by Kalliovirta and Saikkonen (2010) can be performed with the function <code>quantile_residual_tests</code> by providing the estimated model (that is class <code>gmvar</code> object) as an argument.</p>
<p>For graphical diagnostics one may use the function <code>diagostic_plot</code>, which enables one to plot the quantile residual time series, auto- and cross-correlation functions of quantile residuals or their squares, or quantile residual histograms and normal QQ-plots.</p>
</div>
<div id="constructing-a-gmvar-model-without-estimation" class="section level3">
<h3>Constructing a GMVAR model without estimation</h3>
<p>One may wish to construct an arbitrary GMVAR model without any estimation process, for example in order to simulate from a particular process of interest. An arbitrary model can be created with the function <code>GMVAR</code>. If one wants to add or update data to the model afterwards, it’s advisable to use the function <code>add_data</code>.</p>
</div>
<div id="simulating-from-gmvar-process" class="section level3">
<h3>Simulating from GMVAR process</h3>
<p>The function <code>simulateGMVAR</code> is the one for the job. As the main argument it uses a <code>gmvar</code> object created with <code>fitGMVAR</code> or <code>GMVAR</code>.</p>
</div>
<div id="forecasting-gmvar-process" class="section level3">
<h3>Forecasting GMVAR process</h3>
<p>The package <code>gmvarkit</code> contains predict method <code>predict.gmvar</code> for forecasting GMVAR processes. For one step predictions using the exact formula for conditional mean is supported, but the forecasts further than that are based on independent simulations. The predictions are either sample means or medians and the confidence intervals are based on sample quantiles. The objects generated by <code>predict.gmvar</code> have their own plot method. We also encourage directly using the function <code>simulateGMVAR</code> for forecasting.</p>
</div>
<div id="univariate-analysis" class="section level3">
<h3>Univariate analysis</h3>
<p>Use the package <code>uGMAR</code> for analysing univariate time series.</p>
</div>
</div>
<div id="references" class="section level2">
<h2>References</h2>
<ul>
<li>Kalliovirta L., Meitz M. and Saikkonen P. (2016) Gaussian mixture vector autoregression. <em>Journal of Econometrics</em>, <strong>192</strong>, 485-498.</li>
<li>Kalliovirta L. and Saikkonen P. (2010) Reliable Residuals for Multivariate Nonlinear Time Series Models. <em>Unpublished Revision of HECER Discussion Paper No. 247</em>.</li>
</ul>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>For univariate analysis one may use the package <code>uGMAR</code>.<a href="#fnref1" class="footnote-back">↩</a></p></li>
</ol>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
